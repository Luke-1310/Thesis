APPUNTI SUI DIVERSI FILE PRESENTI NEL PROGETTO, AGGIORNATO AL 28/07/2025

**q_learning_training.py:**

La Q-table è una tabella che usa un agente di Q-learning (tipologia di reinforcement learning) per imparare quale azione fare in ogni stato.
    Ogni riga rappresenta uno stato (ad esempio: "sono all'incrocio, il semaforo è rosso").
    Ogni colonna rappresenta una azione possibile (tipo "vai dritto", "gira a destra", "aspetta").
    Ogni valore dentro la tabella (Q-value) dice quanto è buona quell'azione in quello stato.

def train_agent(env, font): passati enviornment e font, tale funzione ha come scopo quello di addestrare l'agente con diversi parametri.

def evaluate_agent(env, font): si occupa di valutare l'agente, scegliendo tramite np.argmax... (173) l'azione migliore da compiere;
    chiaramente ci sono due esiti finali, il raggiungimento del parcheggio oppure il fallimento.

def show_menu(screen, font): passandogli il font e l'interfaccia dove disegnare (finestra) viene disegnato un menu grafico per l'utente

def draw_text(screen, text, x, y, font, color=(0,0,0), center=False): funzione per stampare testo su schermo

def show_yes_no_dialog(screen, font, question): mostra all'utente se vuole vedere o no i risultati

def select_map(screen, font): permette di scegliere la mappa all'utente e ritorna la classe della mappa selezionata

def show_training_results(screen, font, episode_data): stampa il resecondo del training dell'agente

def show_settings(screen, font, env): funzione attua nel gestire le impostazioni del simulatore

def show_training_charts(screen, font, episode_data, cumulative_collisions, env): per stampare i grafici con i risultati delle simulazioni

def main

**base_environment.py:**

**map1_environment.py:**

**map2_environment.py:**
